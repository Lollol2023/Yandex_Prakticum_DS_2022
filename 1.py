#!/usr/bin/env python
# coding: utf-8

# <div style="border:solid purple 2px; padding: 20px">
# 
# Привет! 👋 Поздравляю с первым выполненным проектом.
#     
# Меня зовут Рустам Муртазин, и я буду делать ревью твоей работы. Давай будем общаться на **«ты»**. Если это неприемлемо, обязательно напиши мне в комментариях — мы перейдем на **«вы»**.
# 
# Проделана большая работа над проектом, однако в любом деле всегда можно можно что-то улучшить. Моя основная цель — не показать, что где-то совершены какие-либо ошибки, а поделиться своим опытом, который поможет тебе в дальнейших работах. Далее в файле ты сможешь увидеть мои комментарии, постарайся учесть их при выполнении следующих заданий.    
# 
# Обрати внимание в первую очередь на те, что помечаны <span style="color:red">красным цветом</span>. После их доработки проект будет принят. <span style="color:green">Зеленым цветом</span> отмечены удачные и элегантные решения, на которые можно опираться в будущих проектах. <span style="color:orange">Оранжевым цветом</span> выделено то, что в следующий раз можно сделать по-другому. Ты можешь учесть эти комментарии при выполнении будущих заданий или доработать проект сейчас (однако это не обязательно). Также в проекте могут быть небольшие «лайфхаки» по Python, не относящиеся к проекту, их я выделил в фиолетовую рамку)
# 
# Давай работать над проектом в диалоге: если ты **что-то меняешь** в проекте по моим рекомендациям — **пиши об этом**. Выбери для своих комментариев какой-то заметный цвет, так мне будет легче отследить изменения. Пожалуйста, **не перемещай, не изменяй и не удаляй мои комментарии**. Всё это поможет выполнить повторную проверку твоего проекта оперативнее».
# 
# ---
# 
# Обратная связь после проверки:
# 
# - Работа сделана на очень хорошем уровне, ты делаешь успехи уже на первом проекте!
# - Здорово освоен groupby - это очень полезный инструмент.
# - Функции реализованы корректно и лаконично
# - Отдельно хочу похвалить за то, что соблюдаешь чистоту кода - такой код приятно читать.
# - По ходу работы я оставил комментарии по улучшению проекта. Надеюсь, они будут тебе полезны.
#     
# Проект принят, успехов в дальнейшем обучении!
# 
# ![](https://i.ibb.co/ctpSFFc/good-job.gif)
# 
# 
# </div>
# 

# # Яндекс.Музыка

# Сравнение Москвы и Петербурга окружено мифами. Например:
#  * Москва — мегаполис, подчинённый жёсткому ритму рабочей недели;
#  * Петербург — культурная столица, со своими вкусами.
# 
# На данных Яндекс.Музыки вы сравните поведение пользователей двух столиц.
# 
# **Цель исследования** — проверьте три гипотезы:
# 1. Активность пользователей зависит от дня недели. Причём в Москве и Петербурге это проявляется по-разному.
# 2. В понедельник утром в Москве преобладают одни жанры, а в Петербурге — другие. Так же и вечером пятницы преобладают разные жанры — в зависимости от города. 
# 3. Москва и Петербург предпочитают разные жанры музыки. В Москве чаще слушают поп-музыку, в Петербурге — русский рэп.
# 
# **Ход исследования**
# 
# Данные о поведении пользователей вы получите из файла `yandex_music_project.csv`. О качестве данных ничего не известно. Поэтому перед проверкой гипотез понадобится обзор данных. 
# 
# Вы проверите данные на ошибки и оцените их влияние на исследование. Затем, на этапе предобработки вы поищете возможность исправить самые критичные ошибки данных.
#  
# Таким образом, исследование пройдёт в три этапа:
#  1. Обзор данных.
#  2. Предобработка данных.
#  3. Проверка гипотез.
# 
# 

# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Отличное введение! Не забывай о нем в следующих проектах тоже 😉. Эту часть пользователь отчета видит самой первой и из нее становится понятно, чему работа посвящена. И еще, старайся его не копипастить, а переписать своими словами, это позволит перейти тебе на новый уровень оформления работы 
# 

# ## Обзор данных
# 
# Составьте первое представление о данных Яндекс.Музыки.
# 
# 
# 

# Основной инструмент аналитика — `pandas`. Импортируйте эту библиотеку.

# In[1]:


import pandas as pd


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Правильно, что используешь сокращение pd для pandas - это общепринятое сокращение (также как и np для numpy) и именно pd ты будешь встречать на всех сайтах, где будешь искать информацию при обучении (а умение искать информацию, код - одно из ключевых в нашем деле).
# 

# Прочитайте файл `yandex_music_project.csv` из папки `/datasets` и сохраните его в переменной `df`:

# In[2]:


df = pd.read_csv('/datasets/yandex_music_project.csv')# чтение файла с данными и сохранение в df


# <div class="alert alert-success"> 
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Файл загружен корректно 👍 Кстати, если будешь делать проекты локально, не забывай менять пути к файлам. Здесь удобно  использовать конструкцию `try-except` для путей файлов. Например: Try - пути на локальном компьютере, except - пути на сервере. Тогда твой проект будет всегда работать и локально, и в тренажере.

# Выведите на экран первые десять строк таблицы:

# In[3]:


display(df.head(10))


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Первый взгляд на сырые данные - это важная часть любого исследования. Кстати, ты знаешь про методы [tail](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html) и [sample](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html)? Если нет, то обязательно почитай на досуге)
# 

# Одной командой получить общую информацию о таблице:

# In[4]:


df.info()# получение общей информации о данных в таблице df


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Пайплан первичной обработки можно усилить добавив [describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) 
# 

# Итак, в таблице семь столбцов. Тип данных во всех столбцах — `object`.
# 
# Согласно документации к данным:
# * `userID` — идентификатор пользователя;
# * `Track` — название трека;  
# * `artist` — имя исполнителя;
# * `genre` — название жанра;
# * `City` — город пользователя;
# * `time` — время начала прослушивания;
# * `Day` — день недели.
# 
# В названиях колонок видны три нарушения стиля:
# 1. Строчные буквы сочетаются с прописными.
# 2. Встречаются пробелы.
# 3. **Верблюжий регистр - в пременной userID нет разделителя "_"**
# 
# 
# 
# Количество значений в столбцах различается. Значит, в данных есть пропущенные значения.
# 

# <div class="alert alert-success"> 
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Абсолютно верно!

# **Выводы**
# 
# В каждой строке таблицы — данные о прослушанном треке. Часть колонок описывает саму композицию: название, исполнителя и жанр. Остальные данные рассказывают о пользователе: из какого он города, когда он слушал музыку. 
# 
# Предварительно можно утверждать, что, данных достаточно для проверки гипотез. Но встречаются пропуски в данных, а в названиях колонок — расхождения с хорошим стилем.
# 
# Чтобы двигаться дальше, нужно устранить проблемы в данных.

# ## Предобработка данных
# Исправьте стиль в заголовках столбцов, исключите пропуски. Затем проверьте данные на дубликаты.

# ### Стиль заголовков
# Выведите на экран названия столбцов:

# In[5]:


display(df.columns)# перечень названий столбцов таблицы df


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# `display()` в данном случае можно не использовать, так как df.columns последней строкой (даже единственной) в блоке и она все равно выведется на экран.
# 

# Приведите названия в соответствие с хорошим стилем:
# * несколько слов в названии запишите в «змеином_регистре»,
# * все символы сделайте строчными,
# * устраните пробелы.
# 
# Для этого переименуйте колонки так:
# * `'  userID'` → `'user_id'`;
# * `'Track'` → `'track'`;
# * `'  City  '` → `'city'`;
# * `'Day'` → `'day'`.

# In[39]:


df = df.rename(columns = {'  userID':'user_id','Track':'track','  City  ':'city','Day':'day'})# переименование столбцов


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Можно разнести записи в слове на разные строки, порой так наглядее:
# 
# ```python
# df = df.rename(columns={'  userID': 'user_id', 
#                         'Track': 'track', 
#                         '  City  ': 'city', 
#                         'Day': 'day'})
# ```
# 

# Проверьте результат. Для этого ещё раз выведите на экран названия столбцов:

# In[7]:


display(df.columns)# проверка результатов - перечень названий столбцов


# ### Пропуски значений
# Сначала посчитайте, сколько в таблице пропущенных значений. Для этого достаточно двух методов `pandas`:

# In[8]:


df.isna().sum()# подсчёт пропусков


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Кстати, правильно, что используешь `isna()` вместо `isnull()`. Методы аналогичны, но `isnull()` является копией (alias) для `isna()`, поэтому это является best practice. (Чуть подробнее про это можно почитать [здесь](https://stackoverflow.com/questions/52086574/pandas-isna-and-isnull-what-is-the-difference).)
# 

# Не все пропущенные значения влияют на исследование. Так в `track` и `artist` пропуски не важны для вашей работы. Достаточно заменить их явными обозначениями.
# 
# Но пропуски в `genre` могут помешать сравнению музыкальных вкусов в Москве и Санкт-Петербурге. На практике было бы правильно установить причину пропусков и восстановить данные. Такой возможности нет в учебном проекте. Придётся:
# * заполнить и эти пропуски явными обозначениями,
# * оценить, насколько они повредят расчётам. 

# Замените пропущенные значения в столбцах `track`, `artist` и `genre` на строку `'unknown'`. Для этого создайте список `columns_to_replace`, переберите его элементы циклом `for` и для каждого столбца выполните замену пропущенных значений:

# In[9]:


# перебор названий столбцов в цикле и замена пропущенных значений на 'unknown'
columns_to_replace = ['track', 'artist', 'genre']
for i in columns_to_replace:
    df[i] = df[i].fillna('unknown')


# <div class="alert alert-warning">
# <h2> Комментарий ревьюера ⚠️ <a class="tocSkip"> </h2>
# 
# Хорошее решение, но по мне цикл здесь лишний, ведь ты заменяешь все пропуски на одно значение и можно выполнить замену разом для всего датафрейма, т.е так
# ```python
# df[columns_to_replace]=df[columns_to_replace].fillna('unknown')
# ```
# 

# Убедитесь, что в таблице не осталось пропусков. Для этого ещё раз посчитайте пропущенные значения.

# In[10]:


# подсчёт пропусков
df.isna().sum()


# ### Дубликаты
# Посчитайте явные дубликаты в таблице одной командой:

# In[11]:


df.duplicated().sum()


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Дааааа, многовато...
# 
# ![](https://i.ibb.co/s13m30m/C2pL.gif)
# 

# Вызовите специальный метод `pandas`, чтобы удалить явные дубликаты:

# In[12]:


df = df.drop_duplicates().reset_index()# удаление явных дубликатов (с удалением старых индексов и формированием новых)


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Все круто. Сбросить индексы - отличное решение, на мой взгляд, так лучше.
# 

# Ещё раз посчитайте явные дубликаты в таблице — убедитесь, что полностью от них избавились:

# In[13]:


df.duplicated().sum()# проверка на отсутствие дубликатов


# Теперь избавьтесь от неявных дубликатов в колонке `genre`. Например, название одного и того же жанра может быть записано немного по-разному. Такие ошибки тоже повлияют на результат исследования.

# Выведите на экран список уникальных названий жанров, отсортированный в алфавитном порядке. Для этого:
# * извлеките нужный столбец датафрейма, 
# * примените к нему метод сортировки,
# * для отсортированного столбца вызовите метод, который вернёт уникальные значения из столбца.

# In[40]:


display(df['genre'].sort_values().unique())
# Просмотр уникальных названий жанров


# Просмотрите список и найдите неявные дубликаты названия `hiphop`. Это могут быть названия с ошибками или альтернативные названия того же жанра.
# 
# Вы увидите следующие неявные дубликаты:
# * *hip*,
# * *hop*,
# * *hip-hop*.
# 
# Чтобы очистить от них таблицу, напишите функцию `replace_wrong_genres()` с двумя параметрами: 
# * `wrong_genres` — список дубликатов,
# * `correct_genre` — строка с правильным значением.
# 
# Функция должна исправить колонку `genre` в таблице `df`: заменить каждое значение из списка `wrong_genres` на значение из `correct_genre`.

# In[15]:


# Функция для замены неявных дубликатов
def replace_wrong_genres(wrong_genres,correct_genre):
    for wrong_genre in wrong_genres:
        df['genre'] = df['genre'].replace(wrong_genre,correct_genre)

wrong_genres = ['hip','hop','hip-hop']
correct_genre = 'hiphop'


# Вызовите `replace_wrong_genres()` и передайте ей такие аргументы, чтобы она устранила неявные дубликаты: вместо `hip`, `hop` и `hip-hop` в таблице должно быть значение `hiphop`:

# In[16]:


# Устранение неявных дубликатов
replace_wrong_genres(wrong_genres,correct_genre)


# <div class="alert alert-success">
# <h2> Комментарий ревьюера <a class="tocSkip"> </h2>
# 
# Небольшое упрощение, опять-таки связано со списками. Так можно заменить эти значения с помощью одного реплейса:
#     
# ```python
# duplicates = ['hip', 'hop', 'hip-hop']
# correct_name = 'hiphop'  
# 
# df['genre'] = df['genre'].replace(duplicates, correct_name)
# ```
# 
# Программа посмотрит на список duplicates и каждое встречающееся в Series значение из этого списка заменит на correct_name. Можно сделать и так:
# 
#     
# ```python
# df['genre'] = df['genre'].replace(['hip', 'hop', 'hip-hop'], 'hiphop')
# ```
# 

# Проверьте, что заменили неправильные названия:
# 
# *   hip
# *   hop
# *   hip-hop
# 
# Выведите отсортированный список уникальных значений столбца `genre`:

# In[41]:


# Проверка на неявные дубликаты
display(df['genre'].sort_values().unique())


# **Выводы**
# 
# Предобработка обнаружила три проблемы в данных:
# 
# - нарушения в стиле заголовков,
# - пропущенные значения,
# - дубликаты — явные и неявные.
# 
# Вы исправили заголовки, чтобы упростить работу с таблицей. Без дубликатов исследование станет более точным.
# 
# Пропущенные значения вы заменили на `'unknown'`. Ещё предстоит увидеть, не повредят ли исследованию пропуски в колонке `genre`.
# 
# Теперь можно перейти к проверке гипотез. 

# <div class="alert alert-success">
# <h2> Комментарий ревьюера <a class="tocSkip"> </h2>
# 
# Здорово, когда шаг заканчивается выводом - что сделали, к чему пришли. Это хорошая практика, прошу придерживаться ее и в следующих проектах.
# 

# ## Проверка гипотез

# ### Сравнение поведения пользователей двух столиц

# Первая гипотеза утверждает, что пользователи по-разному слушают музыку в Москве и Санкт-Петербурге. Проверьте это предположение по данным о трёх днях недели — понедельнике, среде и пятнице. Для этого:
# 
# * Разделите пользователей Москвы и Санкт-Петербурга
# * Сравните, сколько треков послушала каждая группа пользователей в понедельник, среду и пятницу.
# 

# Для тренировки сначала выполните каждый из расчётов по отдельности. 
# 
# Оцените активность пользователей в каждом городе. Сгруппируйте данные по городу и посчитайте прослушивания в каждой группе.
# 
# 

# In[42]:


# Подсчёт прослушиваний в каждом городе
df.groupby('city')['genre'].count()


# В Москве прослушиваний больше, чем в Петербурге. Из этого не следует, что московские пользователи чаще слушают музыку. Просто самих пользователей в Москве больше.
# 
# Теперь сгруппируйте данные по дню недели и подсчитайте прослушивания в понедельник, среду и пятницу. Учтите, что в данных есть информация только о прослушиваниях только за эти дни.
# 

# In[43]:


# Подсчёт прослушиваний в каждый из трёх дней
df.groupby('day')['genre'].count()


# В среднем пользователи из двух городов менее активны по средам. Но картина может измениться, если рассмотреть каждый город в отдельности.

# Вы видели, как работает группировка по городу и по дням недели. Теперь напишите функцию, которая объединит два эти расчёта.
# 
# Создайте функцию `number_tracks()`, которая посчитает прослушивания для заданного дня и города. Ей понадобятся два параметра:
# * день недели,
# * название города.
# 
# В функции сохраните в переменную строки исходной таблицы, у которых значение:
#   * в колонке `day` равно параметру `day`,
#   * в колонке `city` равно параметру `city`.
# 
# Для этого примените последовательную фильтрацию с логической индексацией.
# 
# Затем посчитайте значения в столбце `user_id` получившейся таблицы. Результат сохраните в новую переменную. Верните эту переменную из функции.

# In[20]:


# <создание функции number_tracks()>
def number_tracks(day, city): # Объявляется функция с двумя параметрами: day, city.
    track_list = df[df['day'] == day]# В переменной track_list сохраняются те строки таблицы df, для которых
    # значение в столбце 'day' равно параметру day и одновременно значение
    track_list = track_list[track_list['city'] == city] # в столбце 'city' равно параметру city (используйте последовательную фильтрацию
    # с помощью логической индексации).
    track_list_count = track_list['user_id'].count() # В переменной track_list_count сохраняется число значений столбца 'user_id',
    # рассчитанное методом count() для таблицы track_list.
    return track_list_count # Функция возвращает число - значение track_list_count.

# Функция для подсчёта прослушиваний для конкретного города и дня.
# С помощью последовательной фильтрации с логической индексацией она 
# сначала получит из исходной таблицы строки с нужным днём,
# затем из результата отфильтрует строки с нужным городом,
# методом count() посчитает количество значений в колонке user_id. 
# Это количество функция вернёт в качестве результата


# <div class="alert alert-warning">
# <h2> Комментарий ревьюера ⚠️ <a class="tocSkip"> </h2>
# 
# Описание для функции принято оборачивать в тройные скобки, вот так
#     
# ```python
# def return_2x(number):
#     '''Функция возвращает число умноженное на два'''
#     return 2 * number
# ```
#     
# Тогда, если во время применения функции, мы захотим прочитать описание функции, мы можем зажать `Tab+Shift`, и в поле `Docstring` мы как раз увидим наше описание
#     
# ![](https://i.ibb.co/0qr42jL/image.png)
#     
# Посмотри на документацию [pandas](https://github.com/pandas-dev/pandas/blob/v1.3.0/pandas/core/generic.py#L9694-L9764), там примерно та же конструкция, только немного усложненная)
# 

# Вызовите `number_tracks()` шесть раз, меняя значение параметров — так, чтобы получить данные для каждого города в каждый из трёх дней.

# In[44]:


# количество прослушиваний в Москве по понедельникам
number_tracks('Monday', 'Moscow')


# In[22]:


# количество прослушиваний в Санкт-Петербурге по понедельникам
number_tracks('Monday', 'Saint-Petersburg')


# In[45]:


# количество прослушиваний в Москве по средам
number_tracks('Wednesday', 'Moscow')


# In[24]:


# количество прослушиваний в Санкт-Петербурге по средам
number_tracks('Wednesday', 'Saint-Petersburg')


# In[46]:


# количество прослушиваний в Москве по пятницам
number_tracks('Friday', 'Moscow')


# In[26]:


# количество прослушиваний в Санкт-Петербурге по пятницам
number_tracks('Friday', 'Saint-Petersburg')


# <div class="alert alert-success"> 
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Для общего развития вот пример, как можно было реализовать все в цикле.
# 
# ```python
# for weekday, city in zip(['Monday', 'Wednesday', 'Friday']*2, sorted(['Moscow', 'Saint-Petersburg']*3)):
#     print(f'Количество прослушиваний в {city} по {weekday} равно {number_tracks(weekday, city)}')
# ```
# 
# Какие приемы здесь использовались:
# 
# - размножение списков, путем умножения их на число
# - сортировка через `sorted`
# - про `zip`: функция zip создаёт итератор, который комбинирует элементы нескольких списков. Это позволяет осуществлять параллельный обход списков в циклах for или, например, выполнять параллельную сортировку.
# 
# ![](https://i.ibb.co/MPPZ6TL/image.png)
# 
# - про форматирование `f-строками` можно почитать вот [здесь](https://docs-python.ru/tutorial/ispolzovanie-tekstovyh-strok-python/formatirovanie-strok-pechati-sohranenija/)

# Создайте c помощью конструктора `pd.DataFrame` таблицу, где
# * названия колонок — `['city', 'monday', 'wednesday', 'friday']`;
# * данные — результаты, которые вы получили с помощью `number_tracks`.

# In[27]:


# Таблица с результатами


data = [ 
    ['Moscow', 15740, 11056, 15945],
    ['Saint-Petersburg', 5614, 7003, 5895],
    
]    

columns = ['city', 'monday', 'wednesday', 'friday']

table = pd.DataFrame(data = data, columns = columns)
display(table)


# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Удобная и верная сводная таблица 
# 
# ![](https://i.ibb.co/5rKhZ8d/5rN.gif)
# 

# **Выводы**
# 
# Данные показывают разницу поведения пользователей:
# 
# - В Москве пик прослушиваний приходится на понедельник и пятницу, а в среду заметен спад.
# - В Петербурге, наоборот, больше слушают музыку по средам. Активность в понедельник и пятницу здесь почти в равной мере уступает среде.
# 
# Значит, данные говорят в пользу первой гипотезы.

# ### Музыка в начале и в конце недели

# Согласно второй гипотезе, утром в понедельник в Москве преобладают одни жанры, а в Петербурге — другие. Так же и вечером пятницы преобладают разные жанры — в зависимости от города.

# Сохраните таблицы с данными в две переменные:
# * по Москве — в `moscow_general`;
# * по Санкт-Петербургу — в `spb_general`.

# In[47]:


# получение таблицы moscow_general из тех строк таблицы df, 
# для которых значение в столбце 'city' равно 'Moscow'
moscow_general = df[df['city'] == 'Moscow']


# In[48]:


# получение таблицы spb_general из тех строк таблицы df,
# для которых значение в столбце 'city' равно 'Saint-Petersburg'
spb_general = df[df['city'] == 'Saint-Petersburg']


# Создайте функцию `genre_weekday()` с четырьмя параметрами:
# * таблица (датафрейм) с данными,
# * день недели,
# * начальная временная метка в формате 'hh:mm', 
# * последняя временная метка в формате 'hh:mm'.
# 
# Функция должна вернуть информацию о топ-10 жанров тех треков, которые прослушивали в указанный день, в промежутке между двумя отметками времени.

# In[30]:


# Объявление функции genre_weekday() с параметрами table, day, time1, time2,
# которая возвращает информацию о самых популярных жанрах в указанный день в
# заданное время:
# 1) в переменную genre_df сохраняются те строки переданного датафрейма table, для
#    которых одновременно:
#    - значение в столбце day равно значению аргумента day
#    - значение в столбце time больше значения аргумента time1
#    - значение в столбце time меньше значения аргумента time2
#    Используйте последовательную фильтрацию с помощью логической индексации.
# 2) сгруппировать датафрейм genre_df по столбцу genre, взять один из его
#    столбцов и посчитать методом count() количество записей для каждого из
#    присутствующих жанров, получившийся Series записать в переменную
#    genre_df_count
# 3) отсортировать genre_df_count по убыванию встречаемости и сохранить
#    в переменную genre_df_sorted
# 4) вернуть Series из 10 первых значений genre_df_sorted, это будут топ-10
#    популярных жанров (в указанный день, в заданное время)

def genre_weekday(table, day, time1, time2):
    genre_df = table[table['day'] == day]
    genre_df = table[table['time'] > time1]
    genre_df = table[table['time'] < time2]
    genre_df_count = genre_df.groupby('genre')['genre'].count()
    genre_df_sorted = genre_df_count.sort_values(ascending = False)
    return genre_df_sorted.head(10)


# <div style="border:solid purple 5px; padding: 20px"> 
# <h2 align="center"> Рубрика «Питонячий лайфхакер» <a class="tocSkip"> </h2>
# 
# <h3> PEP 8 - руководство по написанию кода на Python  <a class="tocSkip"> </h3>
# 
# В python есть своя философия. Именно отсюда берутся определенные правила и стандарты. В пайтон такое соглашение назвали PEP 8. PEP 8 создан на основе рекомендаций Гуидо ван Россума (создатель языка Python) с добавлениями от Барри Уорсо (соратник).
# 
# Единый стиль оформления делает код понятным для самого программиста и его коллег с разным уровнем подготовки. В идеале наиболее сложный фрагмент кода должен быть понятен с первого прочтения. Это упрощает командную разработку и обучение новичков, позволяет вам быстро возвращаться к собственным давним проектам.
# 
# Каждый уважающий себя питонист обязан знать этот стандарт. Читайте [оригинал](https://www.python.org/dev/peps/pep-0008/) или [перевод](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html), главное  —  вдумчиво!
# 
# Когда проект небольшой, несложно следить за качеством кода, но вот когда проект принимает маштабы ... часто это становиться проблемой. В этом случае выручат скрипты автоматической проверки кода. Кстати, PyCharm проверяет написанное «на лету». А если вы привыкли работать в Jupyter, то на GitHub есть целый раздел [Python Code Quality Authority](https://github.com/PyCQA/), где хранятся утилиты для повышения качества кода, в том числе для проверки стиля на соответствие PEP 8: flake8, pycodestyle, pep8-naming.
# 
# ![](https://i.ibb.co/Gv0PvHQ/mini-magick20171220-84-vtyy26.png)

# Cравните результаты функции `genre_weekday()` для Москвы и Санкт-Петербурга в понедельник утром (с 7:00 до 11:00) и в пятницу вечером (с 17:00 до 23:00):

# In[49]:


# вызов функции для утра понедельника в Москве (вместо df — таблица moscow_general)
# объекты, хранящие время, являются строками и сравниваются как строки
# пример вызова: genre_weekday(moscow_general, 'Monday', '07:00', '11:00')
genre_weekday(moscow_general, 'Monday', '07:00', '11:00')


# In[50]:


# вызов функции для утра понедельника в Петербурге (вместо df — таблица spb_general)
genre_weekday(spb_general, 'Monday', '07:00', '11:00')


# In[51]:


# вызов функции для вечера пятницы в Москве
genre_weekday(moscow_general, 'Friday', '17:00', '23:00')


# In[34]:


# вызов функции для вечера пятницы в Петербурге
genre_weekday(spb_general, 'Friday', '17:00', '23:00')


# <div class="alert alert-success"> 
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Здесь все верно, идем дальше
# 
# ![](https://i.ibb.co/vDCfQgy/2GU.gif)

# **Выводы**
# 
# Если сравнить топ-10 жанров в понедельник утром, можно сделать такие выводы:
# 
# 1. В Москве и Петербурге слушают похожую музыку. Единственное отличие — в московский рейтинг вошёл жанр “world”, а в петербургский — джаз и классика.
# 
# 2. В Москве пропущенных значений оказалось так много, что значение `'unknown'` заняло десятое место среди самых популярных жанров. Значит, пропущенные значения занимают существенную долю в данных и угрожают достоверности исследования.
# 
# Вечер пятницы не меняет эту картину. Некоторые жанры поднимаются немного выше, другие спускаются, но в целом топ-10 остаётся тем же самым.
# 
# Таким образом, вторая гипотеза подтвердилась лишь частично:
# * Пользователи слушают похожую музыку в начале недели и в конце.
# * Разница между Москвой и Петербургом не слишком выражена. В Москве чаще слушают русскую популярную музыку, в Петербурге — джаз.
# 
# Однако пропуски в данных ставят под сомнение этот результат. В Москве их так много, что рейтинг топ-10 мог бы выглядеть иначе, если бы не утерянные  данные о жанрах.

# ### Жанровые предпочтения в Москве и Петербурге
# 
# Гипотеза: Петербург — столица рэпа, музыку этого жанра там слушают чаще, чем в Москве.  А Москва — город контрастов, в котором, тем не менее, преобладает поп-музыка.

# Сгруппируйте таблицу `moscow_general` по жанру и посчитайте прослушивания треков каждого жанра методом `count()`. Затем отсортируйте результат в порядке убывания и сохраните его в таблице `moscow_genres`.

# In[52]:


# одной строкой: группировка таблицы moscow_general по столбцу 'genre', 
# подсчёт числа значений 'genre' в этой группировке методом count(), 
# сортировка получившегося Series в порядке убывания и сохранение в moscow_genres
moscow_genres = moscow_general.groupby('genre')['genre'].count().sort_values(ascending = False)


# Выведите на экран первые десять строк `moscow_genres`:

# In[36]:


# просмотр первых 10 строк moscow_genres
display(moscow_genres.head(10))


# <div class="alert alert-warning">
# <h2> Комментарий ревьюера ⚠️ <a class="tocSkip"> </h2>
# 
# Для красоты Series можно обратно преобразовывать в датафрейм методом `.to_frame()`:
# 
#     moscow_genres.to_frame()
# 

# Теперь повторите то же и для Петербурга.
# 
# Сгруппируйте таблицу `spb_general` по жанру. Посчитайте прослушивания треков каждого жанра. Результат отсортируйте в порядке убывания и сохраните в таблице `spb_genres`:
# 

# In[53]:


# одной строкой: группировка таблицы spb_general по столбцу 'genre', 
# подсчёт числа значений 'genre' в этой группировке методом count(), 
# сортировка получившегося Series в порядке убывания и сохранение в spb_genres
spb_genres = spb_general.groupby('genre')['genre'].count().sort_values(ascending = False)


# Выведите на экран первые десять строк `spb_genres`:

# In[54]:


# просмотр первых 10 строк spb_genres
display(spb_genres.head(10))


# **Выводы**

# Гипотеза частично подтвердилась:
# * Поп-музыка — самый популярный жанр в Москве, как и предполагала гипотеза. Более того, в топ-10 жанров встречается близкий жанр — русская популярная музыка.
# * Вопреки ожиданиям, рэп одинаково популярен в Москве и Петербурге. 
# 

# ## Итоги исследования

# Вы проверили три гипотезы и установили:
# 
# 1. День недели по-разному влияет на активность пользователей в Москве и Петербурге. 
# 
# Первая гипотеза полностью подтвердилась.
# 
# 2. Музыкальные предпочтения не сильно меняются в течение недели — будь то Москва или Петербург. Небольшие различия заметны в начале недели, по понедельникам:
# * в Москве слушают музыку жанра “world”,
# * в Петербурге — джаз и классику.
# 
# Таким образом, вторая гипотеза подтвердилась лишь отчасти. Этот результат мог оказаться иным, если бы не пропуски в данных.
# 
# 3. Во вкусах пользователей Москвы и Петербурга больше общего чем различий. Вопреки ожиданиям, предпочтения жанров в Петербурге напоминают московские.
# 
# Третья гипотеза не подтвердилась. Если различия в предпочтениях и существуют, на основной массе пользователей они незаметны.
# 
# **На практике исследования содержат проверки статистических гипотез.**
# Из данных одного сервиса не всегда можно сделать вывод о всех жителях города.
# Проверки статистических гипотез покажут, насколько они достоверны, исходя из имеющихся данных. 
# С методами проверок гипотез вы ещё познакомитесь в следующих темах.

# <div class="alert alert-success">
# <h2> Комментарий ревьюера ✔️ <a class="tocSkip"> </h2>
# 
# Общий вывод - важная часть исследования. Не забывай про него и в будущих проектах, так как порой пользователь отчета сразу переходит к нему - и из него он должен понять все, что было найдено в ходе исследования.
# 

# In[ ]:




